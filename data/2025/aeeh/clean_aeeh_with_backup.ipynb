{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process\n",
    "- Load backup file\n",
    "- Load DS (Demarches Simplifiees) CSV file\n",
    "- Apply eligibility dates\n",
    "  - 01/01/2006 to 31/12/2019 (inclusives)\n",
    "- Clean & Format the rows\n",
    "  - Add the columns \"is_found\" (default to False),\n",
    "  - Add the column \"folder_number\" (default to np.NaN)\n",
    "- Match DS rows against the backup rows\n",
    "- If match, create boolean column \"is_found\" and set it to True, otherwise False\n",
    "- Output 1 CSV file with the database format (to be injection ready)\n",
    "- Output 1 CSV file for the support team with the created column \"is_found\", and the \"folder_number\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import csv\n",
    "\n",
    "from datetime import datetime, timedelta\n",
    "from dotenv import load_dotenv\n",
    "from utils.data_utils import unaccent_and_upper, format_insee_or_postal_code, get_current_date_for_file_name\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "ds_input_filepath = os.environ['DEMARCHES_SIMPLIFIEES_PATHFILE_2025']\n",
    "backup_input_filepath = os.environ['BACKUP_PATHFILE_2025']\n",
    "grist_input_filepath = os.environ['GRIST_AEEH_CLEANED_PATHFILE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_columns = ['nom', 'prenom', 'date_naissance', 'genre', 'organisme', 'situation', 'allocataire', 'adresse_allocataire', 'created_at', 'updated_at', 'exercice_id', 'uuid_doc', 'zrr', 'qpv', 'a_valider', 'refuser', 'id_psp']\n",
    "db_columns_with_dossier = ['dossier_id', 'nom', 'prenom', 'date_naissance', 'genre', 'organisme', 'situation', 'allocataire', 'adresse_allocataire', 'created_at', 'updated_at', 'exercice_id', 'uuid_doc', 'zrr', 'qpv', 'a_valider', 'refuser', 'id_psp']\n",
    "\n",
    "column_mapping = {\n",
    "  \"ID\" : \"dossier_id\",\n",
    "  \"Email\": \"demandeur_email\",\n",
    "  \"FranceConnect ?\": \"france_connect_a_ete_utilise\",\n",
    "  \"Civilité\": \"qualite\",\n",
    "  \"Nom\": \"demandeur_nom\",\n",
    "  \"Prénom\": \"demandeur_prenom\",\n",
    "  \"Dépôt pour un tiers\": \"depot_pour_un_tiers\",\n",
    "  \"Nom du mandataire\": \"nom_mandataire\",\n",
    "  \"Prénom du mandataire\": \"prenom_mandataire\",\n",
    "  \"À archiver\": \"a_archiver\",\n",
    "  \"État du dossier\": \"etat_dossier\",\n",
    "  \"Dernière mise à jour le\": \"derniere_mise_a_jour\",\n",
    "  \"Dernière mise à jour du dossier le\": \"derniere_mise_a_jour_du_dossier\",\n",
    "  \"Déposé le\": \"depose_le\",\n",
    "  \"Passé en instruction le\": \"passe_en_instruction_le\",\n",
    "  \"Traité le\": \"traite_le\",\n",
    "  \"Motivation de la décision\": \"decision\",\n",
    "  \"Instructeurs\": \"instructeurs\",\n",
    "  \"Percevez-vous l'allocation d'éducation de l'enfant handicapé (AEEH) ?\": \"est_aeeh\",\n",
    "  \"Nom de famille de l'allocataire\": \"allocataire-nom\",\n",
    "  \"Prénom de l'allocataire\": \"allocataire-prenom\",\n",
    "  \"Adresse électronique de l'allocataire\": \"allocataire-courriel\",\n",
    "  \"L'organisme de gestion de votre allocation\": \"organisme\",\n",
    "  \"Adresse de résidence de l'allocataire\": \"adresse_allocataire-voie\",\n",
    "  \"Commune de résidence de l'allocataire\": \"adresse_allocataire-commune\",\n",
    "  \"Commune de résidence de l'allocataire (Code INSEE)\": \"adresse_allocataire-commune_insee\",\n",
    "  \"Commune de résidence de l'allocataire (Département)\": \"adresse_allocataire-departement\",\n",
    "  # \"Le numéro d'allocataire\": \"allocataire-matricule\",\n",
    "  \"Le numéro d'allocataire CAF\": \"allocataire-matricule\",\n",
    "  \"Genre\": \"genre\",\n",
    "  \"Prénom de l'enfant\": \"prenom\",\n",
    "  \"Nom de famille de l'enfant\": \"nom\",\n",
    "  \"Date de naissance de l'enfant\": \"date_naissance\",\n",
    "  \"Attestation de paiement de l'AEEH, fournie par votre CAF ou MSA\": \"attestation_paiement\",\n",
    "  \"Nouvelle annotation\": \"annotation\"\n",
    "}\n",
    "\n",
    "ds_df = pd.read_csv(ds_input_filepath, on_bad_lines='skip', sep=',', dtype=str, engine=\"c\", keep_default_na=False, encoding=\"utf-8\")\n",
    "ds_df = ds_df.rename(columns=column_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_df['etat_dossier'] = ds_df['etat_dossier'].replace('En instruction', 'en_instruction')\n",
    "ds_df['adresse_allocataire-code-postal'] = ds_df['adresse_allocataire-commune'].str.extract(r'\\((\\d{5})\\)')\n",
    "ds_df['adresse_allocataire-commune'] = ds_df['adresse_allocataire-commune'].str.extract(r'(.+)\\s\\(\\d{5}\\)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_caf = ds_df['organisme'] == 'CAF'\n",
    "ds_df.loc[mask_caf, 'allocataire-matricule'] = ds_df.loc[mask_caf, 'allocataire-matricule'].str[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_matricule = ds_df['allocataire-matricule'].str.len() < 7\n",
    "ds_df.loc[mask_caf & mask_matricule, 'allocataire-matricule'] = ds_df.loc[mask_caf & mask_matricule, 'allocataire-matricule'].str.replace(' ', '').str[\n",
    "    :7].str.zfill(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_df['allocataire-qualite'] = np.NaN\n",
    "ds_df['situation'] = 'jeune'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format date_naissance to datetime python object for processing\n",
    "ds_df['date_naissance'] = pd.to_datetime(ds_df['date_naissance'], format='%Y-%m-%d')\n",
    "ds_df['prenom'] = ds_df['prenom'].apply(unaccent_and_upper).str.strip()\n",
    "ds_df['nom'] = ds_df['nom'].apply(unaccent_and_upper).str.strip()\n",
    "ds_df['genre'] = ds_df['genre'].replace({\n",
    "    'M.': 'M',\n",
    "    'Mme': 'F'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6 to 13 years old\n",
    "mask_dob_start = pd.to_datetime(ds_df['date_naissance']).dt.date >= datetime(2012, 1, 1).date()\n",
    "mask_dob_end = pd.to_datetime(ds_df['date_naissance']).dt.date <= datetime(2019, 12, 31).date()\n",
    "\n",
    "ds_df = ds_df[mask_dob_start & mask_dob_end]\n",
    "\n",
    "# add 4h on all birthdates\n",
    "ds_df['date_naissance'] = ds_df['date_naissance'] + timedelta(hours=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map allocataire json\n",
    "def to_json_allocataire_without_null(row):\n",
    "    allocataire_mapping = {\n",
    "        'qualite': np.NaN,\n",
    "        'nom': unaccent_and_upper(row['allocataire-nom']).strip(),\n",
    "        'prenom': unaccent_and_upper(row['allocataire-prenom']).strip(),\n",
    "        'courriel': row['allocataire-courriel'].lower().strip()\n",
    "    }\n",
    "    if row['allocataire-matricule']:\n",
    "        allocataire_mapping['matricule'] = row['allocataire-matricule']\n",
    "    filtered_NaN_allocataire = {k: v for k, v in allocataire_mapping.items() if pd.notnull(v)}\n",
    "    return json.dumps(filtered_NaN_allocataire, ensure_ascii=False)\n",
    "\n",
    "ds_df['allocataire'] = ds_df.apply(to_json_allocataire_without_null, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map adresse_allocataire json\n",
    "def to_json_adresse_without_null(row):\n",
    "    adresse_mapping = {\n",
    "        'voie': unaccent_and_upper(row['adresse_allocataire-voie'].strip()),\n",
    "        'commune': unaccent_and_upper(row['adresse_allocataire-commune'].strip()),\n",
    "        'code_postal': format_insee_or_postal_code(row['adresse_allocataire-code-postal']),\n",
    "        'code_insee': format_insee_or_postal_code(row['adresse_allocataire-commune_insee'])\n",
    "    }\n",
    "    filtered_address = {k: v for k, v in adresse_mapping.items() if pd.notnull(v)}\n",
    "    return json.dumps(filtered_address, ensure_ascii=False)\n",
    "\n",
    "ds_df['adresse_allocataire'] = ds_df.apply(to_json_adresse_without_null, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add missing default column needed to backup data\n",
    "# Put a date value for the 2025 data otherwise the merge will not work as intended (the dates from 2024 will replace the non existing dates on data from 2025)\n",
    "timestamp_with_custom_tz = pd.Timestamp.now(tz='Europe/Paris')\n",
    "\n",
    "exercice_2025 = 4\n",
    "ds_df['exercice_id'] = exercice_2025\n",
    "ds_df[['id_psp', 'uuid_doc']] = np.NaN\n",
    "ds_df[['zrr', 'qpv', 'a_valider', 'refuser']] = False\n",
    "ds_df[['created_at', 'updated_at']] = timestamp_with_custom_tz\n",
    "\n",
    "current_date = datetime.now()\n",
    "current_year = str(current_date.year)[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backup_df_cnaf_2025 = pd.read_csv(backup_input_filepath, sep=';', encoding='utf-8', dtype=str)\n",
    "grist_df_aeeh = pd.read_csv(grist_input_filepath, sep=';', encoding='utf-8', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backup_df_cnaf_2025_unwrapped = pd.json_normalize(backup_df_cnaf_2025['allocataire'].apply(json.loads)).add_prefix('allocataire-')\n",
    "backup_df_cnaf_2025 = pd.merge(backup_df_cnaf_2025, backup_df_cnaf_2025_unwrapped['allocataire-courriel'], left_index=True, right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backup_df = pd.concat([backup_df_cnaf_2025, grist_df_aeeh], ignore_index=True).reset_index()\n",
    "ds_df['date_naissance'] = ds_df['date_naissance'].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(ds_df, backup_df, how='inner', on=['prenom', 'nom', 'date_naissance'], suffixes=('', '_right'))\n",
    "not_eligible_df = ds_df[~ds_df['dossier_id'].isin(merged_df['dossier_id'])]\n",
    "not_eligible_df.reset_index(drop=True).sort_values(by=['dossier_id'])\n",
    "\n",
    "assert((len(not_eligible_df) + len(merged_df)) == len(ds_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique codes generation\n",
    "import random\n",
    "import string\n",
    "import datetime\n",
    "\n",
    "all_eligible = pd.concat([merged_df]).reset_index(drop=True)\n",
    "current_date = datetime.datetime.now()\n",
    "current_year = str(current_date.year)[-2:]\n",
    "\n",
    "def get_characters_set(size = 4):\n",
    "    return ''.join(random.choices([c for c in string.ascii_uppercase if c not in 'OI'], k=size))\n",
    "\n",
    "def generate_code():\n",
    "    return f\"{current_year}-I{get_characters_set(3)}-{get_characters_set(4)}\"\n",
    "\n",
    "# init set of codes with existing\n",
    "unique_codes = set()\n",
    "\n",
    "# init current_code count\n",
    "current_codes_count = len(unique_codes)\n",
    "\n",
    "while len(unique_codes) < len(all_eligible):\n",
    "    unique_codes.add(generate_code())\n",
    "\n",
    "# Ensure we have generated codes for all the rows\n",
    "assert len(unique_codes) == len(all_eligible)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_eligible['id_psp'] = list(unique_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"{len(merged_df)} matches first wave\")\n",
    "print(f\"{len(not_eligible_df)} not eligible from the first wave\")\n",
    "print(f\"{len(all_eligible)} total eligible out of {len(ds_df)}\")\n",
    "print(f\"Success rate first wave {len(merged_df)/len(ds_df):.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output to CSV files\n",
    "all_eligible[db_columns].to_csv(get_current_date_for_file_name('aeeh.csv'), sep=';', index=False, encoding='utf-8', quoting=csv.QUOTE_ALL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
