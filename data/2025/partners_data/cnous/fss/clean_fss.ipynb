{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.data_utils import unaccent_and_upper, format_insee_or_postal_code\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "filepath = os.environ['FSS_PATHFILE_2025']\n",
    "base_output_filepath = os.environ['DB_FSS_EXPORT_2025']\n",
    "exercice_id = 4\n",
    "\n",
    "columns = [\n",
    "  'code_operateur',\n",
    "  'nom',\n",
    "  'prenom',\n",
    "  'date_naissance',\n",
    "  'lieu_naissance',\n",
    "  'genre',\n",
    "  'courriel',\n",
    "  'statut_de_boursier',\n",
    "  'niveau',\n",
    "  'echelon',\n",
    "  'date_debut_rentree',\n",
    "  'duree_versement',\n",
    "  \"nom_etablissement\",\n",
    "  \"ville_etudes\",\n",
    "  'statut_du_boursier',\n",
    "  'numero_dossier_bourse',\n",
    "  'matricule',\n",
    "  \"nom_usage\",\n",
    "  \"uairne_etablissement\",\n",
    "  'date_notification_bourse',\n",
    "  \"date_effet_bourse\",\n",
    "  'date_radiation',\n",
    "  'radiation',\n",
    "  'commune_code_postal',\n",
    "  'commune_code_insee',\n",
    "  'commune_naissance_code_postal'\n",
    "]\n",
    "\n",
    "df = pd.read_csv(filepath, encoding='utf-8', on_bad_lines='skip', sep=';', engine=\"c\", dtype=str, names=columns, header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['date_radiation'].dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cleaning and formatting\n",
    "df['nom'] = df['nom'].astype(str).str.strip().apply(unaccent_and_upper)\n",
    "df['prenom'] = df['prenom'].astype(str).str.strip().apply(unaccent_and_upper)\n",
    "df['qualite'] = df['genre'].replace('F', 'Mme')\n",
    "df['organisme'] = 'cnous'\n",
    "df['situation'] = 'boursier'\n",
    "df['courriel'] = df['courriel'].str.lower()\n",
    "df['date_naissance'] = pd.to_datetime(df['date_naissance'], format='%d/%m/%Y')\n",
    "df['allocataire-date_naissance'] =  pd.to_datetime(df['date_naissance'], format='%d/%m/%Y').dt.strftime('%d/%m/%Y')\n",
    "df['commune_naissance'] = format_insee_or_postal_code(df['lieu_naissance'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply criterias on CNOUS datas\n",
    "from datetime import timedelta\n",
    "\n",
    "mask_dob_start = df['date_naissance'] >= datetime(1997, 1, 1)\n",
    "mask_dob_end = df['date_naissance'] <= datetime(2025, 12, 31)\n",
    "mask_dob = mask_dob_start & mask_dob_end\n",
    "\n",
    "df_filtered = df[mask_dob]\n",
    "\n",
    "print(f\"{len(df) - len(df_filtered)} rows for CNOUS dataframe were removed based on criterias\")\n",
    "print(f\"{len(df_filtered)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows with missing necessary values (if one of those value are missing we cannot generate a code)\n",
    "necessary_column = ['nom', 'prenom', 'date_naissance', 'genre']\n",
    "df_all_valid_row = df_filtered.dropna(subset=necessary_column)\n",
    "\n",
    "# remove columns with all null value\n",
    "df_all_valid = df_all_valid_row.dropna(axis=1, how='all')\n",
    "\n",
    "print(f\"{len(df_all_valid)}\")\n",
    "assert len(df_all_valid[df_filtered['nom'].isnull() | df_all_valid['prenom'].isnull() | df_all_valid['date_naissance'].isnull()]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add 4h on all birthdates\n",
    "df_all_valid.loc[:,'date_naissance'] = df_all_valid['date_naissance'] + timedelta(hours=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map to json values for target DB model\n",
    "## map allocataire json\n",
    "def to_json_allocataire_without_null(row):\n",
    "    allocataire_mapping = {\n",
    "        'qualite': row['qualite'],\n",
    "        'nom': unaccent_and_upper(row['nom']),\n",
    "        'prenom': unaccent_and_upper(row['prenom']),\n",
    "        'date_naissance': row['allocataire-date_naissance'],\n",
    "        'courriel': row['courriel'],\n",
    "        'commune_naissance': format_insee_or_postal_code(row['commune_naissance_code_postal']),\n",
    "        'matricule': row['matricule'],\n",
    "        # These do not exist in the source files\n",
    "        # 'code_insee_commune_naissance': format_insee_or_postal_code(row['commune_code_insee']),\n",
    "        # 'code_iso_pays_naissance': row['allocataire-code_iso_pays_naissance'].upper(),\n",
    "        # 'pays_naissance': get_country_from_iso(row['allocataire-code_iso_pays_naissance'].upper()).upper()\n",
    "    }\n",
    "    filtered_NaN_allocataire = {k: v for k, v in allocataire_mapping.items() if pd.notnull(v) and v != ''}\n",
    "    return json.dumps(filtered_NaN_allocataire, ensure_ascii=False)\n",
    "\n",
    "df_all_valid['allocataire'] = df_all_valid.apply(to_json_allocataire_without_null, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_json_adresse_without_null(row):\n",
    "    adresse_mapping = {\n",
    "        'code_postal': format_insee_or_postal_code(row['commune_code_postal']),\n",
    "        # These do not exist in the source files\n",
    "        # 'voie': unaccent_and_upper(row['adresse-allocataire_voie'].strip()).replace('\"', '\\''),\n",
    "        # 'commune': unaccent_and_upper(row['adresse-allocataire_commune'].strip()),\n",
    "        # 'code_insee': format_insee_or_postal_code(row['commune_code_insee']),\n",
    "    }\n",
    "    \n",
    "    filtered_address = {k: v for k, v in adresse_mapping.items() if pd.notnull(v) and v != ''}\n",
    "    return json.dumps(filtered_address, ensure_ascii=False)\n",
    "\n",
    "df_all_valid['adresse_allocataire'] = df_all_valid.apply(to_json_adresse_without_null, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "existing_codes_filepath = os.environ['EXISTING_CODES_PATHFILE_2025']\n",
    "existing_codes = pd.read_csv(existing_codes_filepath, on_bad_lines='skip', sep=',', engine=\"c\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique codes generation\n",
    "import random\n",
    "import string\n",
    "import datetime\n",
    "\n",
    "current_date = datetime.datetime.now()\n",
    "current_year = str(current_date.year)[-2:]\n",
    "\n",
    "def get_characters_set(size = 4):\n",
    "    return ''.join(random.choices([c for c in string.ascii_uppercase if c not in 'OI'], k=size))\n",
    "\n",
    "def generate_code():\n",
    "    return f\"{current_year}-{get_characters_set(4)}-{get_characters_set(4)}\"\n",
    "\n",
    "# init set of codes with existing\n",
    "unique_codes = set(existing_codes['code'])\n",
    "\n",
    "# init current_code count\n",
    "current_codes_count = len(unique_codes)\n",
    "\n",
    "while len(unique_codes) < (len(df_all_valid) + len(existing_codes)):\n",
    "    unique_codes.add(generate_code())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure we have generated codes for all the rows\n",
    "assert len(unique_codes) == (len(df_all_valid) + len(existing_codes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign generated code for production data\n",
    "new_codes = unique_codes.difference(set(existing_codes['code']))\n",
    "assert len(new_codes) == len(df_all_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_valid['id_psp'] = list(new_codes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add missing default columns needed for target DB model\n",
    "timestamp_with_custom_tz = pd.Timestamp.now(tz='Europe/Paris')\n",
    "\n",
    "df_all_valid.loc[:,'exercice_id'] = exercice_id\n",
    "df_all_valid.loc[:,'uuid_doc'] = np.NaN\n",
    "df_all_valid[['zrr', 'qpv', 'a_valider', 'refuser']] = False\n",
    "df_all_valid[['created_at', 'updated_at']] = timestamp_with_custom_tz\n",
    "len(df_all_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = df_all_valid['courriel'].value_counts()\n",
    "duplicates = counts[counts > 1]\n",
    "print(f\"{len(duplicates)} total duplicates\")\n",
    "df_all_valid = df_all_valid.drop_duplicates(subset=['courriel'], keep=False)\n",
    "len(df_all_valid)\n",
    "print(f\"{len(df_all_valid)} students to inject\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output to CSV\n",
    "db_columns = ['nom', 'prenom', 'date_naissance', 'genre', 'organisme', 'situation', 'allocataire', 'adresse_allocataire', 'created_at', 'updated_at', 'exercice_id', 'uuid_doc', 'zrr', 'qpv', 'a_valider', 'refuser', 'id_psp']\n",
    "\n",
    "df_all_valid[db_columns].to_csv(base_output_filepath, sep=';', index=False, encoding='utf-8')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
