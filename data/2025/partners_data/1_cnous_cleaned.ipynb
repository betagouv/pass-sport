{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Process\n",
    "- Load CNOUS file\n",
    "- Clean data and first mapping for bdd injection\n",
    "- Drop duplicates\n",
    "- Add default column values\n",
    "- Output to CSV\n",
    "\n",
    "## Encoding\n",
    "CNOUS -> windows-1252, check for 2025"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "from data.utils.data_utils import unaccent_and_upper, format_insee_or_postal_code\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "cnous_filepath = os.environ['CNOUS_PATHFILE']\n",
    "base_output_filepath = os.environ['DB_EXPORT']\n",
    "exercice_id = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnous_column_type = {\n",
    "  'lieuNaissCodeCommuneInsee': 'str',\n",
    "  'lieuNaissCodePays': 'str'\n",
    "}\n",
    "\n",
    "cnous_df = pd.read_csv(cnous_filepath, encoding='windows-1252', on_bad_lines='skip', sep=';', engine=\"c\", dtype=cnous_column_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnous_column_mapping = {\n",
    "    # infos allocataire\n",
    "    'ine': 'allocataire-matricule',\n",
    "\n",
    "    # pas de code organisme\n",
    "    'civiliteLibelleCourt': 'allocataire-qualite',\n",
    "    'nom': 'allocataire-nom',\n",
    "    'prenom': 'allocataire-prenom',\n",
    "    'dateNaissance': 'allocataire-date_naissance',\n",
    "    'mail': 'allocataire-courriel',\n",
    "    'lieuNaissCodeCommuneInsee': 'allocataire-code_insee_commune_naissance',\n",
    "    'lieuNaissLibelleCommune': 'allocataire-commune_naissance',\n",
    "    'lieuNaissCodePays': 'allocataire-code_iso_pays_naissance',\n",
    "    'lieuNaissLibellePays': 'allocataire-pays_naissance',\n",
    "\n",
    "    # adresse allocataire\n",
    "    'adresseVoie': 'adresse_allocataire-voie',\n",
    "    'adresseCodePostal': 'adresse_allocataire-code_postal',\n",
    "    'adresseLocalite': 'adresse_allocataire-commune',\n",
    "    'adresseCodeLocalite': 'adresse_allocataire-code_insee',\n",
    "    'adresseComplement1': 'adresse_allocataire-cplt_adresse',\n",
    "\n",
    "    # infos bénéficiaires\n",
    "    'genre': 'civiliteLibelleCourt',\n",
    "}\n",
    "\n",
    "# Drop unused column\n",
    "df_psp_mapped_cnous = cnous_df.copy()\n",
    "df_psp_mapped_cnous.drop(columns=['adresseCodePays', 'adresseComplement2'], inplace=True)\n",
    "\n",
    "df_psp_mapped_cnous.rename(columns=cnous_column_mapping, inplace=True) \n",
    "\n",
    "# organisme\n",
    "df_psp_mapped_cnous['organisme'] = 'cnous'\n",
    "df_psp_mapped_cnous['situation'] = 'boursier'\n",
    "\n",
    "# remove weird values\n",
    "df_psp_mapped_cnous = df_psp_mapped_cnous[df_psp_mapped_cnous['allocataire-date_naissance'] != 'dateNaissance']\n",
    "\n",
    "# infos bénéficiaires = allocataire\n",
    "df_psp_mapped_cnous['date_naissance'] = pd.to_datetime(df_psp_mapped_cnous['allocataire-date_naissance'], format='%d/%m/%Y').dt.strftime('%Y-%m-%d')\n",
    "df_psp_mapped_cnous['allocataire-date_naissance'] =  pd.to_datetime(df_psp_mapped_cnous['allocataire-date_naissance'], format='%d/%m/%Y')\n",
    "df_psp_mapped_cnous['nom'] = df_psp_mapped_cnous['allocataire-nom']\n",
    "df_psp_mapped_cnous['prenom'] = df_psp_mapped_cnous['allocataire-prenom']\n",
    "df_psp_mapped_cnous['genre'] = df_psp_mapped_cnous['allocataire-qualite']\n",
    "df_psp_mapped_cnous['allocataire-qualite'] = df_psp_mapped_cnous['allocataire-qualite'].replace('F', 'Mme')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply criterias on CNOUS datas\n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# Cut off date for eligibility for year 2025\n",
    "end_date = pd.to_datetime('2025-10-15').date()\n",
    "start_date = end_date - relativedelta(years=28)\n",
    "\n",
    "cnous_situation_mask = (df_psp_mapped_cnous['date_naissance'].dt.date >= start_date) & (df_psp_mapped_cnous['date_naissance'].dt.date <= end_date)\n",
    "df_psp_mapped_cnous_filtered = df_psp_mapped_cnous[cnous_situation_mask]\n",
    "\n",
    "print(f\"{len(df_psp_mapped_cnous) - len(df_psp_mapped_cnous_filtered)} rows for CNOUS dataframe were removed based on criterias\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concat into a single dataframe\n",
    "df_all = pd.concat([df_psp_mapped_cnous_filtered], axis=0, ignore_index=True)\n",
    "\n",
    "# remove rows with missing necessary values (if one of those value are missing we cannot generate a code)\n",
    "necessary_column = ['nom', 'prenom', 'date_naissance', 'genre']\n",
    "df_all_valid_row = df_all.dropna(subset=necessary_column)\n",
    "\n",
    "# remove columns with all null value\n",
    "df_all_valid = df_all_valid_row.dropna(axis=1, how='all')\n",
    "\n",
    "assert len(df_all_valid[df_all['nom'].isnull() | df_all_valid['prenom'].isnull() | df_all_valid['date_naissance'].isnull()]) == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Upper case these columns for the merge\n",
    "df_all_valid['prenom'] = df_all_valid['prenom'].astype(str).apply(unaccent_and_upper)\n",
    "df_all_valid['nom'] = df_all_valid['nom'].astype(str).apply(unaccent_and_upper)\n",
    "df_all_valid['genre'] = df_all_valid['genre'].astype(str).apply(unaccent_and_upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lower case on emails on all\n",
    "df_all_valid.loc[:,'allocataire-courriel'] = df_all_valid['allocataire-courriel'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove rows when beneficiary is before september 1994\n",
    "mask_before = pd.to_datetime(df_all_valid['date_naissance']) > datetime(1994, 9, 16)\n",
    "df_all_valid_after = df_all_valid[mask_before]\n",
    "\n",
    "print(f\"{len(df_all_valid) - len(df_all_valid_after)} rows where removed because date_naissance was before 1994\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add missing 0 to phone numbers\n",
    "mask_tel_not_null = df_all_valid_after['allocataire-telephone'].notna()\n",
    "mask_no_zero_phone_number = ~df_all_valid_after.loc[mask_tel_not_null, 'allocataire-telephone'].str.startswith('0')\n",
    "mask_9_char_phone = df_all_valid_after.loc[mask_tel_not_null, 'allocataire-telephone'].str.len() == 9\n",
    "df_all_valid_after.loc[mask_tel_not_null & mask_no_zero_phone_number & mask_9_char_phone, 'allocataire-telephone'] = '0' + df_all_valid_after['allocataire-telephone']\n",
    "\n",
    "# set '0' phone values to None\n",
    "mask_tel_eq_zero = df_all_valid_after['allocataire-telephone'] == '0'\n",
    "df_all_valid_after.loc[mask_tel_eq_zero, 'allocataire-telephone'] = np.NaN\n",
    "\n",
    "# add 4h on all birthdates\n",
    "df_all_valid_after.loc[:,'date_naissance'] = df_all_valid_after['date_naissance'] + timedelta(hours=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove duplicate beneficiaries\n",
    "df_all_valid_no_duplicate = df_all_valid_after.drop_duplicates(subset=[\n",
    "  'date_naissance',\n",
    "  'nom', \n",
    "  'prenom', \n",
    "  'genre', \n",
    "  'organisme', \n",
    "  'situation',\n",
    "  'allocataire-qualite', \n",
    "  'allocataire-matricule',\n",
    "  'allocataire-code_organisme', \n",
    "  'allocataire-telephone',\n",
    "\n",
    "  # 'allocataire-nom', \n",
    "  'allocataire-prenom', \n",
    "  'allocataire-date_naissance',\n",
    "  'allocataire-courriel',\n",
    "\n",
    "  # we can remove this column additionaly\n",
    "  'allocataire-code_insee_commune_naissance',\n",
    "  'allocataire-commune_naissance', \n",
    "  'allocataire-code_iso_pays_naissance',\n",
    "  'allocataire-pays_naissance'\n",
    "])\n",
    "\n",
    "print(f\"{len(df_all_valid_after) - len(df_all_valid_no_duplicate)} duplicate rows were removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map to json values for target DB model \n",
    "## map allocataire json\n",
    "def to_json_allocataire_without_null(row):\n",
    "    allocataire_mapping = {\n",
    "        'qualite': row['allocataire-qualite'],\n",
    "        'matricule': row['allocataire-matricule'],\n",
    "        'code_organisme': row['allocataire-code_organisme'],\n",
    "        'telephone': row['allocataire-telephone'],\n",
    "        'nom': unaccent_and_upper(row['allocataire-nom']),\n",
    "        'prenom': unaccent_and_upper(row['allocataire-prenom']),\n",
    "        'date_naissance': row['allocataire-date_naissance'],\n",
    "        'courriel': row['allocataire-courriel'],\n",
    "        'code_insee_commune_naissance': row['allocataire-code_insee_commune_naissance'],\n",
    "        'commune_naissance': row['allocataire-commune_naissance'],\n",
    "        'code_iso_pays_naissance': row['allocataire-code_iso_pays_naissance'],\n",
    "        'pays_naissance': row['allocataire-pays_naissance']\n",
    "    }\n",
    "    filtered_NaN_allocataire = {k: v for k, v in allocataire_mapping.items() if pd.notnull(v)}\n",
    "    return json.dumps(filtered_NaN_allocataire, ensure_ascii=False)\n",
    "\n",
    "df_all_valid_no_duplicate['allocataire'] = df_all_valid_no_duplicate.apply(to_json_allocataire_without_null, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## map adresse_allocataire json\n",
    "def to_json_adresse_without_null(row):\n",
    "    adresse_mapping = {\n",
    "        'voie': row['adresse_allocataire-voie'],\n",
    "        'code_postal': format_insee_or_postal_code(row['adresse_allocataire-code_postal']),\n",
    "        'nom_adresse_postale': row['adresse_allocataire-nom_adresse_postale'],\n",
    "        'commune': row['adresse_allocataire-commune'],\n",
    "        'code_insee': format_insee_or_postal_code(row['adresse_allocataire-code_insee']),\n",
    "        'cplt_adresse': row['adresse_allocataire-cplt_adresse'],\n",
    "    }\n",
    "    \n",
    "    filtered_address = {k: v for k, v in adresse_mapping.items() if pd.notnull(v)}\n",
    "    return json.dumps(filtered_address, ensure_ascii=False)\n",
    "\n",
    "df_all_valid_no_duplicate['adresse_allocataire'] = df_all_valid_no_duplicate.apply(to_json_adresse_without_null, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## drop null value\n",
    "df_final = df_all_valid_no_duplicate.drop(columns=[\n",
    "  'allocataire-qualite',\n",
    "  'allocataire-matricule',\n",
    "  'allocataire-code_organisme',\n",
    "  'allocataire-nom',\n",
    "  'allocataire-prenom',\n",
    "  'allocataire-telephone',\n",
    "  'allocataire-date_naissance',\n",
    "  'allocataire-courriel',\n",
    "  'allocataire-code_insee_commune_naissance',\n",
    "  'allocataire-commune_naissance',\n",
    "  'allocataire-code_iso_pays_naissance',\n",
    "  'allocataire-pays_naissance',\n",
    "  'adresse_allocataire-voie',\n",
    "  'adresse_allocataire-nom_adresse_postale',\n",
    "  'adresse_allocataire-code_postal',\n",
    "  'adresse_allocataire-commune',\n",
    "  'adresse_allocataire-code_insee',\n",
    "  'adresse_allocataire-cplt_adresse',\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add missing default column needed for target DB model\n",
    "import datetime\n",
    "\n",
    "df_final.loc[:,'updated_at'] = datetime.datetime.now()\n",
    "df_final.loc[:,'exercice_id'] = exercice_id\n",
    "df_final.loc[:,'uuid_doc'] = np.NaN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output to CSV\n",
    "df_final.to_csv(base_output_filepath)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
