{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Traitement des boursiers sanitaires et sociaux de BFC (Bourgogne Franche Comte)\n",
    "\n",
    "\n",
    "## Procedure\n",
    "1. Chargement du fichier boursiers sanitaires et sociaux BFC (Bourgogne Franche Comte)\n",
    "2. Nettoyage des données et premier mapping au bon format de données attendu dans la BDD\n",
    "3. Application des critères sur les données du CNOUS\n",
    "4. Cleanup (date de naissance + 4 heures)\n",
    "5. Ajout des valeurs pour les colonnes par défault (Paris 13 pour commune naissance et code insee naissance)\n",
    "6. Output to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T16:22:50.641651Z",
     "start_time": "2024-12-11T16:22:50.290508Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import json\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "cnous_filepath = os.environ['CNOUS_PATHFILE']\n",
    "\n",
    "base_output_filepath = os.environ['DB_EXPORT']\n",
    "\n",
    "defaults = {\n",
    "  'code_organisme' : '2700',\n",
    "  'code_insee_naissance' : '75113',\n",
    "  'commune_naissance' : 'PARIS',\n",
    "  'code_iso_pays_naissance' : 'FR',\n",
    "  'pays_naissance' : 'FRANCE',\n",
    "  'organisme' : 'cnous',\n",
    "  'situation' : 'boursier'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T16:22:50.656624Z",
     "start_time": "2024-12-11T16:22:50.644981Z"
    }
   },
   "outputs": [],
   "source": [
    "cnous_df = pd.read_csv(cnous_filepath, encoding='utf-8', on_bad_lines='skip', sep=';', engine=\"c\",dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T16:22:50.738615Z",
     "start_time": "2024-12-11T16:22:50.732210Z"
    }
   },
   "outputs": [],
   "source": [
    "# map CNOUS\n",
    "cnous_column_mapping = {\n",
    "  'a-matricule': 'allocataire-matricule',\n",
    "   # M or MME\n",
    "  'a-qualite': 'allocataire-qualite',\n",
    "  'nom': 'allocataire-nom',\n",
    "  'prenom': 'allocataire-prenom',\n",
    "  'date_naissance': 'allocataire-date_naissance',\n",
    "  'a-courriel': 'allocataire-courriel',\n",
    "  'a-telephone': 'allocataire-telephone',\n",
    "\n",
    "  # adresse allocataire\n",
    "  'a-a-voie': 'adresse_allocataire-voie',\n",
    "  'a-a-code_postal': 'adresse_allocataire-code_postal',\n",
    "  'a-a-commune': 'adresse_allocataire-commune',\n",
    "\n",
    "  # Add leading 0, some have only 4 digits ...\n",
    "  'a-a-code_insee': 'adresse_allocataire-code_insee',\n",
    "  'a-a-cplt_adresse': 'adresse_allocataire-cplt_adresse',\n",
    "  'a-a-nom_adresse_postale': 'adresse_allocataire-nom_adresse_postale',\n",
    "\n",
    "  # infos bénéficiaires\n",
    "  # M for M,\n",
    "  # MME for F\n",
    "  'genre': 'genre',\n",
    "}\n",
    "\n",
    "# Drop unused column\n",
    "df_psp_mapped_cnous = cnous_df.copy()\n",
    "\n",
    "df_psp_mapped_cnous.drop(columns=[\n",
    "    'a-code_insee_commune_naissance', 'a-commune_naissance', 'a-code_iso_pays_naissance', 'a-nom', 'a-prenom', 'a-date_naissance'\n",
    "], inplace=True)\n",
    "\n",
    "df_psp_mapped_cnous.rename(columns=cnous_column_mapping, inplace=True)\n",
    "\n",
    "# organisme\n",
    "df_psp_mapped_cnous['organisme'] = defaults['organisme']\n",
    "df_psp_mapped_cnous['situation'] = defaults['situation']\n",
    "\n",
    "# We hardcode those since the boursiers from BFC (Bourgogne Franche Comté) do not have these\n",
    "# And in the form pass Sport, it will be automatically bypassed\n",
    "df_psp_mapped_cnous['allocataire-code_iso_pays_naissance'] = defaults['code_iso_pays_naissance']\n",
    "df_psp_mapped_cnous['allocataire-pays_naissance'] = defaults['pays_naissance']\n",
    "df_psp_mapped_cnous['allocataire-code_insee_commune_naissance'] = defaults['code_insee_naissance']\n",
    "df_psp_mapped_cnous['allocataire-commune_naissance'] = defaults['commune_naissance']\n",
    "\n",
    "# Unique code organisme for this list of boursiers sanitaires et sociaux BFC\n",
    "df_psp_mapped_cnous['allocataire-code_organisme'] = defaults['code_organisme']\n",
    "\n",
    "df_psp_mapped_cnous['nom'] = df_psp_mapped_cnous['allocataire-nom']\n",
    "df_psp_mapped_cnous['prenom'] = df_psp_mapped_cnous['allocataire-prenom']\n",
    "\n",
    "df_psp_mapped_cnous['genre'] = df_psp_mapped_cnous['allocataire-qualite'].str.strip().replace('MME', 'F')\n",
    "df_psp_mapped_cnous['allocataire-qualite'] = df_psp_mapped_cnous['allocataire-qualite'].str.strip().replace({'MME': 'Mme', 'M': 'M'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T16:22:50.756824Z",
     "start_time": "2024-12-11T16:22:50.745945Z"
    }
   },
   "outputs": [],
   "source": [
    "# Birth date\n",
    "df_psp_mapped_cnous['date_naissance'] = pd.to_datetime(\n",
    "    df_psp_mapped_cnous['allocataire-date_naissance'],\n",
    "    format='%m/%d/%y'\n",
    ")\n",
    "\n",
    "df_psp_mapped_cnous['allocataire-date_naissance'] = df_psp_mapped_cnous['date_naissance'].dt.strftime('%m/%d/%y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T16:22:50.769517Z",
     "start_time": "2024-12-11T16:22:50.764303Z"
    }
   },
   "outputs": [],
   "source": [
    "# apply criterias on CNOUS datas\n",
    "from datetime import timedelta\n",
    "from dateutil.relativedelta import relativedelta\n",
    "\n",
    "# Cut off date for eligibility for year 2024 \n",
    "end_date = pd.to_datetime('2024-10-15').date()\n",
    "start_date = end_date - relativedelta(years=28)\n",
    "\n",
    "cnous_situation_mask = (df_psp_mapped_cnous['date_naissance'].dt.date >= start_date) & (\n",
    "    df_psp_mapped_cnous['date_naissance'].dt.date <= end_date)\n",
    "\n",
    "df_psp_mapped_cnous_filtered = df_psp_mapped_cnous[cnous_situation_mask]\n",
    "\n",
    "print(f\"{len(df_psp_mapped_cnous) - len(df_psp_mapped_cnous_filtered)} rows for CNOUS dataframe were removed based on criterias\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Merge dans un seul dataframe cible pour BDD Postgresql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T16:22:50.785650Z",
     "start_time": "2024-12-11T16:22:50.779554Z"
    }
   },
   "outputs": [],
   "source": [
    "# concat into a single dataframe\n",
    "df_all = pd.concat([df_psp_mapped_cnous_filtered], axis=0, ignore_index=True)\n",
    "\n",
    "# remove rows with missing necessary values (if one of those value are missing we cannot generate a code)\n",
    "necessary_column = ['nom', 'prenom', 'date_naissance', 'genre']\n",
    "df_all_valid_row = df_all.dropna(subset=necessary_column)\n",
    "\n",
    "# remove columns with all null value\n",
    "df_all_valid = df_all_valid_row.dropna(axis=1, how='all')\n",
    "\n",
    "assert len(\n",
    "  df_all_valid[df_all['nom'].isnull() | df_all_valid['prenom'].isnull() | df_all_valid['date_naissance'].isnull()]\n",
    ") == 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T16:22:50.801079Z",
     "start_time": "2024-12-11T16:22:50.799295Z"
    }
   },
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "def unaccent_and_upper(text):\n",
    "    text = unicodedata.normalize('NFKD', text)\n",
    "    text = text.encode('ASCII', 'ignore').decode('utf-8')\n",
    "    return text.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T16:22:50.818888Z",
     "start_time": "2024-12-11T16:22:50.815014Z"
    }
   },
   "outputs": [],
   "source": [
    "# Upper case these columns for the merge\n",
    "df_all_valid['prenom'] = df_all_valid['prenom'].astype(str).apply(unaccent_and_upper)\n",
    "df_all_valid['nom'] = df_all_valid['nom'].astype(str).apply(unaccent_and_upper)\n",
    "df_all_valid['genre'] = df_all_valid['genre'].astype(str).apply(lambda x: x.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T16:22:50.835257Z",
     "start_time": "2024-12-11T16:22:50.833080Z"
    }
   },
   "outputs": [],
   "source": [
    "# lower case on emails on all\n",
    "df_all_valid['allocataire-courriel'] = df_all_valid['allocataire-courriel'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T16:22:50.854445Z",
     "start_time": "2024-12-11T16:22:50.850062Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove rows when beneficiary is before september 1993\n",
    "mask_before_1993 = pd.to_datetime(df_all_valid['date_naissance']) > datetime(1993, 9, 16)\n",
    "df_all_valid_after93 = df_all_valid[mask_before_1993]\n",
    "\n",
    "print(f\"{len(df_all_valid) - len(df_all_valid_after93)} rows where removed because date_naissance was before 1993\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T16:22:50.872752Z",
     "start_time": "2024-12-11T16:22:50.870709Z"
    }
   },
   "outputs": [],
   "source": [
    "# add 4h on all birthdates\n",
    "df_all_valid_after93.loc[:, 'date_naissance'] = df_all_valid_after93['date_naissance'] + timedelta(hours=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T16:22:50.893397Z",
     "start_time": "2024-12-11T16:22:50.889243Z"
    }
   },
   "outputs": [],
   "source": [
    "# remove duplicate beneficiaries\n",
    "df_all_valid_no_duplicate = df_all_valid_after93.drop_duplicates(subset=[\n",
    "  'date_naissance',\n",
    "  'nom',\n",
    "  'prenom',\n",
    "  'genre',\n",
    "  'organisme',\n",
    "  'situation',\n",
    "  'allocataire-qualite',\n",
    "  'allocataire-matricule',\n",
    "  'allocataire-prenom',\n",
    "  'allocataire-date_naissance',\n",
    "  'allocataire-courriel'\n",
    "])\n",
    "\n",
    "print(f\"{len(df_all_valid_after93) - len(df_all_valid_no_duplicate)} duplicate rows were removed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T16:22:51.000123Z",
     "start_time": "2024-12-11T16:22:50.955400Z"
    }
   },
   "outputs": [],
   "source": [
    "# map to json values for target DB model \n",
    "## map allocataire json\n",
    "def to_json_allocataire_without_null(row):\n",
    "  allocataire_mapping = {\n",
    "    'qualite': row['allocataire-qualite'],\n",
    "    'matricule': row['allocataire-matricule'],\n",
    "    'nom': row['allocataire-nom'],\n",
    "    'prenom': row['allocataire-prenom'],\n",
    "    'date_naissance': row['allocataire-date_naissance'],\n",
    "    'courriel': row['allocataire-courriel'],\n",
    "    'telephone': row['allocataire-telephone'],\n",
    "    'code_insee_commune_naissance': row['allocataire-code_insee_commune_naissance'],\n",
    "    'commune_naissance': row['allocataire-commune_naissance'],\n",
    "    'code_iso_pays_naissance': row['allocataire-code_iso_pays_naissance'],\n",
    "    'pays_naissance': row['allocataire-pays_naissance'],\n",
    "    'code_organisme': row['allocataire-code_organisme']\n",
    "  }\n",
    "  filtered_NaN_allocataire = {k: v for k, v in allocataire_mapping.items() if pd.notnull(v)}\n",
    "  return json.dumps(filtered_NaN_allocataire, ensure_ascii=False)\n",
    "\n",
    "\n",
    "df_all_valid_no_duplicate['allocataire'] = df_all_valid_no_duplicate.apply(to_json_allocataire_without_null, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T16:22:51.073134Z",
     "start_time": "2024-12-11T16:22:51.021633Z"
    }
   },
   "outputs": [],
   "source": [
    "## map adresse_allocataire json\n",
    "def to_json_adresse_without_null(row):\n",
    "  adresse_mapping = {\n",
    "    'voie': row['adresse_allocataire-voie'],\n",
    "    'code_postal': format(pd.to_numeric(row['adresse_allocataire-code_postal'], errors='coerce'), '05d'),\n",
    "    'commune': row['adresse_allocataire-commune'],\n",
    "    'code_insee': format(pd.to_numeric(row['adresse_allocataire-code_insee'], errors='coerce'), '05d'),\n",
    "    'cplt_adresse': str(row['adresse_allocataire-cplt_adresse']).replace(\"\\\"\", ''),\n",
    "    'nom_adresse_postale': row['adresse_allocataire-nom_adresse_postale'],\n",
    "  }\n",
    "\n",
    "  filtered_address = {k: v for k, v in adresse_mapping.items() if pd.notnull(v)}\n",
    "  return json.dumps(filtered_address, ensure_ascii=False)\n",
    "\n",
    "\n",
    "df_all_valid_no_duplicate['adresse_allocataire'] = df_all_valid_no_duplicate.apply(to_json_adresse_without_null, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T16:22:51.130678Z",
     "start_time": "2024-12-11T16:22:51.128054Z"
    }
   },
   "outputs": [],
   "source": [
    "## drop null value\n",
    "df_final = df_all_valid_no_duplicate.drop(columns=[\n",
    "  'allocataire-qualite',\n",
    "  'allocataire-matricule',\n",
    "  'allocataire-nom',\n",
    "  'allocataire-prenom',\n",
    "  'allocataire-date_naissance',\n",
    "  'allocataire-courriel',\n",
    "  'allocataire-telephone',\n",
    "  'allocataire-code_insee_commune_naissance',\n",
    "  'allocataire-commune_naissance',\n",
    "  'allocataire-code_iso_pays_naissance',\n",
    "  'allocataire-pays_naissance',\n",
    "  'allocataire-code_organisme',\n",
    "  'adresse_allocataire-voie',\n",
    "  'adresse_allocataire-code_postal',\n",
    "  'adresse_allocataire-commune',\n",
    "  'adresse_allocataire-code_insee',\n",
    "  'adresse_allocataire-cplt_adresse',\n",
    "  'adresse_allocataire-nom_adresse_postale',\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T16:22:51.171274Z",
     "start_time": "2024-12-11T16:22:51.149733Z"
    }
   },
   "outputs": [],
   "source": [
    "import pytz\n",
    "from datetime import datetime\n",
    "\n",
    "tz = pytz.timezone('Europe/Paris')\n",
    "now = datetime.now()\n",
    "now_tz = tz.localize(now)\n",
    "\n",
    "# Add missing default column needed for target DB model\n",
    "df_final['id'] = np.NaN\n",
    "df_final['exercice_id'] = 3\n",
    "df_final['uuid_doc'] = np.NaN\n",
    "df_final['id_psp'] = np.NaN\n",
    "df_final[['zrr', 'qpv', 'a_valider', 'refuser']] = False\n",
    "df_final[['created_at', 'updated_at']] = now_tz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T16:22:53.779781Z",
     "start_time": "2024-12-11T16:22:51.190960Z"
    }
   },
   "outputs": [],
   "source": [
    "# load all existing codes\n",
    "existing_codes_db_filepath = os.environ['DB_EXISTING_CODES']\n",
    "\n",
    "df_existing_codes = pd.read_csv(existing_codes_db_filepath, encoding='utf-8', dtype=str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T16:22:53.802803Z",
     "start_time": "2024-12-11T16:22:53.799371Z"
    }
   },
   "outputs": [],
   "source": [
    "df_no_code = df_final[df_final['id_psp'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T16:22:56.290549Z",
     "start_time": "2024-12-11T16:22:53.823896Z"
    }
   },
   "outputs": [],
   "source": [
    "# generate new code ensuring no duplicates with existings\n",
    "import random\n",
    "import string\n",
    "import datetime\n",
    "\n",
    "current_date = datetime.datetime.now()\n",
    "current_year = str(current_date.year)[-2:]\n",
    "\n",
    "def get_characters_set(size = 4):\n",
    "    return ''.join(random.choices([c for c in string.ascii_uppercase if c not in 'OI'], k=size))\n",
    "\n",
    "def generate_code():\n",
    "    return f\"{current_year}-{get_characters_set(4)}-{get_characters_set(4)}\"\n",
    "\n",
    "# init set of codes with existing\n",
    "unique_codes = set(df_existing_codes['id_psp'])\n",
    "\n",
    "# init current_code count\n",
    "current_codes_count = len(unique_codes)\n",
    "\n",
    "while len(unique_codes) < current_codes_count + len(df_no_code):\n",
    "    code = generate_code()\n",
    "    unique_codes.add(code)\n",
    "\n",
    "# only retrieve newly created codes\n",
    "new_codes = list(unique_codes.difference(df_existing_codes['id_psp']))\n",
    "df_new_codes = pd.DataFrame({ 'id_psp': new_codes })\n",
    "\n",
    "print(f\"{len(df_new_codes)} generated codes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T16:23:02.089628Z",
     "start_time": "2024-12-11T16:23:02.072016Z"
    }
   },
   "outputs": [],
   "source": [
    "df_no_code = df_no_code.reset_index(drop=True).combine_first(df_new_codes.reset_index(drop=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-11T16:23:02.153292Z",
     "start_time": "2024-12-11T16:23:02.094092Z"
    }
   },
   "outputs": [],
   "source": [
    "df_no_code[[\n",
    "    'id',\n",
    "    'id_psp',\n",
    "    'nom',\n",
    "    'prenom',\n",
    "    'date_naissance',\n",
    "    'genre',\n",
    "    'organisme',\n",
    "    'situation',\n",
    "    'allocataire',\n",
    "    'adresse_allocataire',\n",
    "    'created_at',\n",
    "    'updated_at',\n",
    "    'qpv',\n",
    "    'a_valider',\n",
    "    'exercice_id',\n",
    "    'zrr',\n",
    "    'uuid_doc',\n",
    "    'refuser'\n",
    "]].to_csv('./with-codes.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
