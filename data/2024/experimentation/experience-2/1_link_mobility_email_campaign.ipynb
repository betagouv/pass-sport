{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DITP experimentation n°2 - part 1\n",
    "# Notebook for LM campaign on the 19th september that begins on the 26th of september\n",
    "Analysis deadlines: 10 october, 10 november, 31 december\n",
    "\n",
    "- 8 files are to be generated by this script\n",
    "  - 4 files for parents\n",
    "  - 4 files for direct beneficiaires\n",
    "- The CSV format is similar to the previous campaign, except that there is a new column named \"pronom\" whose value can be \"il\" or \"elle\"\n",
    "- 1 file that will contain exhaustive information about these 8 files is also generated for further analysis with DITP later on at step 3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "from datetime import date\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "db_export_filepath = os.environ['DB_EXPORT_PEOPLE_NOT_ACTIVATED_PASS_SPORT_PATHFILE']\n",
    "\n",
    "# Will contain exhaustive information to be re-used later for DITP analysis to update people who activated their pass sport\n",
    "consolidated_output_pathfile = os.environ['CAMPAIGN_LINK_MOBILITY_19_SEPTEMBER_CONSOLIDATED_OUTPUT_PATHFILE']\n",
    "\n",
    "# 4 benef & 4 parents files will be generated at the end\n",
    "benef_part_file_format = os.environ['CAMPAIGN_SPLITTED_FILES_BENEF_OUTPUT_PREFIX']\n",
    "parent_part_file_format = os.environ['CAMPAIGN_SPLITTED_FILES_PARENTS_OUTPUT_PREFIX']\n",
    "\n",
    "qr_code_secret_key = os.environ['BENEF_2024_QR_CODE_URL_SECRET']\n",
    "qr_code_base_url = os.environ['BENEF_2024_QR_CODE_BASE_URL']\n",
    "\n",
    "# rgpd users\n",
    "# Combine with the relative path to the file\n",
    "pathfile_rgpd_users_blacklist =os.path.join('..', os.environ['RGPD_USERS_BLACKLIST_CSV_PATH_FILE']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the two merged CSV (with ids and without ids)\n",
    "columns = ['id', 'nom', 'prenom', 'genre', 'allocataire', 'adresse_allocataire', 'id_psp','date_naissance', 'zrr', 'qpv']\n",
    "\n",
    "df_db = pd.read_csv(db_export_filepath, sep=',', usecols=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unwrap alloc\n",
    "df_json_allocataire = pd.json_normalize(df_db['allocataire'].apply(json.loads))\n",
    "df_json_allocataire = df_json_allocataire.add_prefix('allocataire-')\n",
    "\n",
    "df_db.index = pd.RangeIndex(start=0, stop=len(df_db), step=1)\n",
    "\n",
    "df_db_unwrapped = pd.merge(\n",
    "  df_db, \n",
    "  df_json_allocataire[\n",
    "    ['allocataire-courriel', 'allocataire-qualite', 'allocataire-nom', 'allocataire-prenom', 'allocataire-telephone', 'allocataire-date_naissance']\n",
    "  ], \n",
    "  left_index=True, \n",
    "  right_index=True\n",
    ")\n",
    "\n",
    "df_db_unwrapped = df_db_unwrapped.drop(columns=['allocataire'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unwrap adresse alloc\n",
    "df_json_adresse_allocataire = pd.json_normalize(df_db['adresse_allocataire'].apply(json.loads))\n",
    "\n",
    "df_db_unwrapped.index = pd.RangeIndex(start=0, stop=len(df_db), step=1)\n",
    "\n",
    "df_db_unwrapped = pd.merge(df_db_unwrapped, df_json_adresse_allocataire[['code_postal']], left_index=True, right_index=True)\n",
    "df_db_unwrapped = df_db_unwrapped.drop(columns=['adresse_allocataire'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorized check for 'allocataire-courriel' and 'allocataire-telephone' being empty or NaN\n",
    "mask_contact_empty = ((df_db_unwrapped['allocataire-courriel'].isna()) | (df_db_unwrapped['allocataire-courriel'] == '')) & \\\n",
    "                     ((df_db_unwrapped['allocataire-telephone'].isna()) | (df_db_unwrapped['allocataire-telephone'] == ''))\n",
    "\n",
    "# Vectorized check for any of the 'nom', 'prenom', 'date_naissance', 'genre' being empty or NaN\n",
    "mask_info_missing = (df_db_unwrapped[['nom', 'prenom', 'date_naissance', 'genre']].isna().any(axis=1)) | \\\n",
    "                    ((df_db_unwrapped[['nom', 'prenom', 'date_naissance', 'genre']] == '').any(axis=1))\n",
    "\n",
    "# Final mask\n",
    "mask_email_info_missing = mask_contact_empty | mask_info_missing\n",
    "\n",
    "df_db_unwrapped_reachable = df_db_unwrapped[~mask_email_info_missing]\n",
    "print(f\"{len(df_db_unwrapped) - len(df_db_unwrapped_reachable)} rows deleted because they are not reachable by email or phone\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns\n",
    "column_mapping = {\n",
    "    'allocataire-courriel': 'email',\n",
    "    'allocataire-qualite': 'allocataire_qualite',\n",
    "    'allocataire-nom': 'allocataire_nom',\n",
    "    'allocataire-prenom': 'allocataire_prenom',\n",
    "    'allocataire-telephone': 'telephone',\n",
    "    'prenom': 'beneficiaire_prenom',\n",
    "    'nom': 'beneficiaire_nom',\n",
    "    'genre': 'beneficiaire_genre',\n",
    "    'date_naissance': 'beneficiaire_date_naissance',\n",
    "    'id_psp': 'code',\n",
    "    'allocataire-date_naissance': 'allocataire_date_naissance'\n",
    "}\n",
    "\n",
    "df_db_unwrapped_reachable.columns = df_db_unwrapped_reachable.columns.to_series().replace(column_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep necessary columns\n",
    "df_campaign = df_db_unwrapped_reachable[['email',\n",
    "                                         'allocataire_nom',\n",
    "                                         'allocataire_prenom',\n",
    "                                         'allocataire_date_naissance',\n",
    "                                         'allocataire_qualite',\n",
    "                                         'beneficiaire_prenom',\n",
    "                                         'beneficiaire_nom',\n",
    "                                         'beneficiaire_genre',\n",
    "                                         'beneficiaire_date_naissance', \n",
    "                                         'code', \n",
    "                                         'telephone',\n",
    "                                         'zrr',\n",
    "                                         'qpv',\n",
    "                                         'code_postal',\n",
    "                                         'id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.notion.so/Suivi-remont-s-utilisateurs-0bfd5c50ac67460a99ef651e3f8a0f45?pvs=4#cd6cbf85cbe6498c8ebbeda96ecba42d\n",
    "df_rgpd = pd.read_csv(pathfile_rgpd_users_blacklist, usecols=['email'], dtype={ 'email': 'string' })\n",
    "df_campaign = df_campaign.loc[~df_campaign['email'].isin(df_rgpd['email'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cast to date_time benef + allocataire birth dates\n",
    "df_campaign['beneficiaire_date_naissance'] = pd.to_datetime(df_campaign['beneficiaire_date_naissance'], errors='coerce')\n",
    "df_campaign['allocataire_date_naissance'] = pd.to_datetime(df_campaign['allocataire_date_naissance'], errors='coerce')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column for beneficiaire gender\n",
    "df_campaign['neele'] = 'Né le'\n",
    "mask_girl = df_campaign['beneficiaire_genre'] == 'F'\n",
    "df_campaign.loc[mask_girl, 'neele'] =  'Née le'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column for allocataire gender\n",
    "df_campaign['allocataire_genre'] = np.where(df_campaign['allocataire_qualite'] == 'Mme', 'F', 'M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# capitalize on name / surname\n",
    "df_campaign['allocataire_prenom'] = df_campaign['allocataire_prenom'].astype(str).str.capitalize()\n",
    "df_campaign['allocataire_nom'] = df_campaign['allocataire_nom'].astype(str).str.capitalize()\n",
    "df_campaign['beneficiaire_prenom'] = df_campaign['beneficiaire_prenom'].astype(str).str.capitalize()\n",
    "df_campaign['beneficiaire_nom'] = df_campaign['beneficiaire_nom'].astype(str).str.capitalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# internationalize phone_number\n",
    "df_campaign['telephone'] = df_campaign['telephone'].replace('^0', '+33', regex=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_new_benef = df_campaign['id'].isna()\n",
    "\n",
    "df_campaign_existing = df_campaign[~mask_new_benef]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"il\", \"elle\" values for column \"pronom\"\n",
    "df_campaign_existing['pronom'] = np.where(df_campaign_existing['beneficiaire_genre'] == 'M', 'il', 'elle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# age of beneficiaire + allocataire (if it exists)\n",
    "def calculate_age(born):\n",
    "    today = date.today()\n",
    "    age = today.year - born.year\n",
    "    if (today.month, today.day) < (born.month, born.day):\n",
    "        age -= 1\n",
    "    \n",
    "    return age\n",
    "\n",
    "df_campaign_existing['beneficiaire_age'] = df_campaign_existing['beneficiaire_date_naissance'].apply(calculate_age)\n",
    "df_campaign_existing['allocataire_age'] = df_campaign_existing['allocataire_date_naissance'].apply(calculate_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_campaign_existing[['beneficiaire_age', 'allocataire_age']] = df_campaign_existing[['beneficiaire_age', 'allocataire_age']].astype('Int64')  # Nullable integer type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format date naissance\n",
    "df_campaign_existing['beneficiaire_date_naissance'] = pd.to_datetime(df_campaign_existing['beneficiaire_date_naissance'], format='%d-%m-%Y')\n",
    "df_campaign_existing['beneficiaire_date_naissance'] = df_campaign_existing['beneficiaire_date_naissance'].dt.strftime('%d/%m/%Y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Génération des URLs pour le QR code\n",
    "import urllib.parse\n",
    "import base64\n",
    "\n",
    "from Crypto.Cipher import AES\n",
    "from Crypto.Util.Padding import pad\n",
    "\n",
    "base_64_key = base64.b64decode(qr_code_secret_key)\n",
    "key_mapping = { \n",
    "  'beneficiaire_prenom': 'bp', \n",
    "  'beneficiaire_nom': 'bn', \n",
    "  'beneficiaire_genre' : 'bg', \n",
    "  'beneficiaire_date_naissance': 'bdn', \n",
    "  'code': 'c'\n",
    "}\n",
    "\n",
    "def encrypt(data):\n",
    "    cipher = AES.new(base_64_key, AES.MODE_CBC)\n",
    "    ct_bytes = cipher.encrypt(pad(data.encode('utf-8'), AES.block_size))\n",
    "    iv = cipher.iv\n",
    "    ct = base64.b64encode(iv + ct_bytes).decode('utf-8')\n",
    "    return ct\n",
    "\n",
    "def generate_encrypted_url_column(row):\n",
    "    params = {key_mapping.get(column): row[column] for column in df_campaign.columns}\n",
    "    cleaned_params = {k: v for k, v in params.items() if k is not None}\n",
    "    encoded_params = urllib.parse.urlencode(cleaned_params)\n",
    "    encoded_encrypted_params = encrypt(encoded_params)\n",
    "    full_url_string = f\"{qr_code_base_url}#{urllib.parse.quote_plus(encoded_encrypted_params)}\"\n",
    "    return full_url_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generation des QR code\n",
    "if 'url_qr_code' in df_campaign_existing:\n",
    "    del df_campaign_existing['url_qr_code']\n",
    "    \n",
    "df_campaign_existing['url_qr_code'] = df_campaign_existing.apply(generate_encrypted_url_column, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe that contains all information to update information for DITP later on in october/november/december\n",
    "df_campaign_existing_consolidated = df_campaign_existing.copy()\n",
    "\n",
    "# Dataframe for Link Mobility\n",
    "df_campaign_existing = df_campaign_existing[[\n",
    "  'email',\n",
    "  'allocataire_nom',\n",
    "  'allocataire_prenom',\n",
    "  'beneficiaire_prenom',\n",
    "  'beneficiaire_nom',\n",
    "  'beneficiaire_genre',\n",
    "  'beneficiaire_date_naissance',\n",
    "  'code',\n",
    "  'telephone',\n",
    "  'neele',\n",
    "  'pronom',\n",
    "  'url_qr_code'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# existing rows, case allocataire != bénéficiaire\n",
    "mask_alloc_diff_benef = df_campaign_existing['beneficiaire_prenom'].str.lower() != df_campaign_existing['allocataire_prenom'].str.lower()\n",
    "df_campaign_existing_alloc_diff_benef = df_campaign_existing[mask_alloc_diff_benef]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# existing rows, case allocataire == bénéficiaire\n",
    "mask_alloc_eq_benef = df_campaign_existing['beneficiaire_prenom'].str.lower() == df_campaign_existing['allocataire_prenom'].str.lower()\n",
    "df_campaign_existing_alloc_eq_benef = df_campaign_existing[mask_alloc_eq_benef]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_campaign_existing_alloc_eq_benef_shuffled = df_campaign_existing_alloc_eq_benef.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "df_campaign_existing_alloc_diff_benef_shuffled = df_campaign_existing_alloc_diff_benef.sample(frac=1, random_state=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_campaign_existing_alloc_eq_benef_shuffled_split = np.array_split(df_campaign_existing_alloc_eq_benef_shuffled, 4)\n",
    "df_campaign_existing_alloc_diff_benef_shuffled_split = np.array_split(df_campaign_existing_alloc_diff_benef_shuffled, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direct beneficiaires splitted into 4 equal length files\n",
    "for i, split_df in enumerate(df_campaign_existing_alloc_eq_benef_shuffled_split, start=1):\n",
    "    filename = f'{benef_part_file_format}-{i}.csv'\n",
    "    split_df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parents splitted into 4 equal length files\n",
    "for i, split_df in enumerate(df_campaign_existing_alloc_diff_benef_shuffled_split, start=1):\n",
    "    filename = f'{parent_part_file_format}-{i}.csv'\n",
    "    split_df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save exhaustive dataframe that contains information that are removed for LM mailing campaign\n",
    "# this will be used later for DITP analysis\n",
    "df_campaign_existing_consolidated.to_csv(consolidated_output_pathfile, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
